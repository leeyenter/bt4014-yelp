{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Dictionary & Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-13T04:24:45.136880Z",
     "start_time": "2019-04-13T04:24:45.119925Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c183f60e3e14717b1f1f9df7b2242a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import random\n",
    "import re\n",
    "\n",
    "import gensim\n",
    "import pandas as pd\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from IPython.display import HTML, Markdown, display\n",
    "from tabulate import tabulate\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "tqdm_notebook().pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-13T04:24:45.893630Z",
     "start_time": "2019-04-13T04:24:45.648287Z"
    }
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\", disable=[\"parser\", \"ner\", \"textcat\"])\n",
    "\n",
    "skip = {'$', 'CD'}\n",
    "def tokenise(text):\n",
    "    if type(text) != str:\n",
    "        return []\n",
    "    text = text.replace('\\n\\n', '.').replace('\\n', '.').replace('!', '.').replace('?', '.').replace('.', '. ')\n",
    "    while '  ' in text:\n",
    "        text = text.replace('  ', ' ')\n",
    "    doc = nlp(text, disable=[\"parser\", \"ner\", \"textcat\"])\n",
    "    tokens = []\n",
    "    for token in doc:\n",
    "        if (not token.is_punct and token.tag_ not in skip):\n",
    "            if token.lemma_ == '-PRON-':\n",
    "                tokens.append(token.text.lower())\n",
    "            else:\n",
    "                tokens.append(token.lemma_)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-13T04:24:46.386255Z",
     "start_time": "2019-04-13T04:24:46.380284Z"
    }
   },
   "outputs": [],
   "source": [
    "def tokenise(text):\n",
    "    skip = {'$', 'CD', \"POS\"}\n",
    "    if type(text) != str:\n",
    "        return []\n",
    "    text = text.replace('\\n\\n', '.').replace('\\n', '.').replace('.', '. ')\n",
    "    while '  ' in text:\n",
    "        text = text.replace('  ', ' ')\n",
    "    doc = nlp(text, disable=[\"parser\", \"ner\", \"textcat\"])\n",
    "    tokens = []\n",
    "    for token in doc:\n",
    "        if (not token.is_stop and not token.is_punct and token.tag_ not in skip and len(token) > 2):\n",
    "            if token.lemma_ == '-PRON-':\n",
    "                tokens.append(token.text.lower())\n",
    "            else:\n",
    "                tokens.append(token.lemma_)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-13T05:46:34.451947Z",
     "start_time": "2019-04-13T05:46:07.158915Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7f023c8a35348b099e5f68d496400df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=6919), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "business_name = \"In-N-Out Burger\"\n",
    "df = pd.read_parquet(\"data/\" + business_name + '_reviews.parquet')\n",
    "#tokens = df.text.progress_apply(gensim.parsing.preprocess_string)\n",
    "tokens = df.text.progress_apply(tokenise)\n",
    "tokens = list(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-13T05:46:34.803016Z",
     "start_time": "2019-04-13T05:46:34.452945Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c567b96849a5449a80a861d19d2e9dfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=6919), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dictionary = gensim.corpora.Dictionary(tokens)\n",
    "dictionary.filter_extremes(no_below=10, no_above=0.3, keep_n=None)\n",
    "\n",
    "corpus = [0] * len(tokens)\n",
    "\n",
    "for i in tqdm_notebook(range(len(tokens))):\n",
    "    corpus[i] = dictionary.doc2bow(tokens[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-11T15:04:51.552262Z",
     "start_time": "2019-04-11T15:04:51.546278Z"
    }
   },
   "source": [
    "# Model Building & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-13T04:46:58.186688Z",
     "start_time": "2019-04-13T04:46:58.183683Z"
    }
   },
   "outputs": [],
   "source": [
    "list_num_topics = [2, 4, 6, 8, 10]\n",
    "list_passes = [10, 15, 20, 25, 30]\n",
    "done = set()\n",
    "\n",
    "results = []\n",
    "for i in range(len(list_passes)):\n",
    "    results.append([str(list_passes[i]) + \" passes\"] + [\" \"] * len(list_num_topics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-13T04:54:08.803625Z",
     "start_time": "2019-04-13T04:46:58.187672Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2476d075be234ac6864ce32e84d9fd9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num topics: 2 , passes: 10 : 0.40033\n",
      "num topics: 2 , passes: 15 : 0.39726\n",
      "num topics: 2 , passes: 20 : 0.40255\n",
      "num topics: 2 , passes: 25 : 0.40255\n",
      "num topics: 2 , passes: 30 : 0.41561\n",
      "num topics: 4 , passes: 10 : 0.43407\n",
      "num topics: 4 , passes: 15 : 0.44121\n",
      "num topics: 4 , passes: 20 : 0.45252\n",
      "num topics: 4 , passes: 25 : 0.45827\n",
      "num topics: 4 , passes: 30 : 0.4627\n",
      "num topics: 6 , passes: 10 : 0.46261\n",
      "num topics: 6 , passes: 15 : 0.48628\n",
      "num topics: 6 , passes: 20 : 0.48428\n",
      "num topics: 6 , passes: 25 : 0.49948\n",
      "num topics: 6 , passes: 30 : 0.50265\n",
      "num topics: 8 , passes: 10 : 0.45979\n",
      "num topics: 8 , passes: 15 : 0.47176\n",
      "num topics: 8 , passes: 20 : 0.47287\n",
      "num topics: 8 , passes: 25 : 0.47892\n",
      "num topics: 8 , passes: 30 : 0.48082\n",
      "num topics: 10 , passes: 10 : 0.45708\n",
      "num topics: 10 , passes: 15 : 0.46277\n",
      "num topics: 10 , passes: 20 : 0.47434\n",
      "num topics: 10 , passes: 25 : 0.48171\n",
      "num topics: 10 , passes: 30 : 0.48636\n"
     ]
    }
   ],
   "source": [
    "# while len(done) < len(list_num_topics) * len(list_passes) * 0.8:\n",
    "#     topics_index = random.choice(range(len(list_num_topics)))\n",
    "#     passes_index = random.choice(range(len(list_passes)))\n",
    "for topics_index in tqdm_notebook(range(len(list_num_topics))):\n",
    "    for passes_index in range(len(list_passes)):\n",
    "        num_topics = list_num_topics[topics_index]\n",
    "        passes = list_passes[passes_index]\n",
    "#         tup = (num_topics, passes)\n",
    "#         if tup in done:\n",
    "#             continue\n",
    "        coherence = 0\n",
    "        num_tries = 1\n",
    "        for i in range(num_tries):\n",
    "            lda_model = gensim.models.ldamulticore.LdaMulticore(corpus=corpus,\n",
    "                                                                id2word=dictionary,\n",
    "                                                                num_topics=num_topics, \n",
    "                                                                random_state=i,\n",
    "                                                                chunksize=500,\n",
    "                                                                passes=passes,\n",
    "                                                                workers=7,\n",
    "                                                                per_word_topics=True)\n",
    "            cm = CoherenceModel(model=lda_model, texts=tokens, dictionary=dictionary, coherence='c_v')\n",
    "            coherence += cm.get_coherence()\n",
    "#         done.add(tup)\n",
    "        coherence = round(coherence / num_tries, 5)\n",
    "        print(\"num topics:\", num_topics, \", passes:\", passes, \":\", coherence)\n",
    "        results[passes_index][topics_index+1] = coherence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-13T04:54:08.809593Z",
     "start_time": "2019-04-13T04:54:08.803625Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## In-N-Out Burger"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>No. Pass  </th><th style=\"text-align: right;\">  2 topics</th><th style=\"text-align: right;\">  4 topics</th><th style=\"text-align: right;\">  6 topics</th><th style=\"text-align: right;\">  8 topics</th><th style=\"text-align: right;\">  10 topics</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>10 passes </td><td style=\"text-align: right;\">   0.40033</td><td style=\"text-align: right;\">   0.43407</td><td style=\"text-align: right;\">   0.46261</td><td style=\"text-align: right;\">   0.45979</td><td style=\"text-align: right;\">    0.45708</td></tr>\n",
       "<tr><td>15 passes </td><td style=\"text-align: right;\">   0.39726</td><td style=\"text-align: right;\">   0.44121</td><td style=\"text-align: right;\">   0.48628</td><td style=\"text-align: right;\">   0.47176</td><td style=\"text-align: right;\">    0.46277</td></tr>\n",
       "<tr><td>20 passes </td><td style=\"text-align: right;\">   0.40255</td><td style=\"text-align: right;\">   0.45252</td><td style=\"text-align: right;\">   0.48428</td><td style=\"text-align: right;\">   0.47287</td><td style=\"text-align: right;\">    0.47434</td></tr>\n",
       "<tr><td>25 passes </td><td style=\"text-align: right;\">   0.40255</td><td style=\"text-align: right;\">   0.45827</td><td style=\"text-align: right;\">   0.49948</td><td style=\"text-align: right;\">   0.47892</td><td style=\"text-align: right;\">    0.48171</td></tr>\n",
       "<tr><td>30 passes </td><td style=\"text-align: right;\">   0.41561</td><td style=\"text-align: right;\">   0.4627 </td><td style=\"text-align: right;\">   0.50265</td><td style=\"text-align: right;\">   0.48082</td><td style=\"text-align: right;\">    0.48636</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(\"## \" + business_name))\n",
    "display(HTML(tabulate(results, tablefmt='html', headers=[\"No. Pass\"] + [str(x) + ' topics' for x in list_num_topics])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display Model Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-13T05:47:34.059272Z",
     "start_time": "2019-04-13T05:46:34.804009Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# In-N-Out Burger: 6 topics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>Topic #  </th><th>Term 1  </th><th>Term 2  </th><th>Term 3  </th><th>Term 4  </th><th>Term 5  </th><th>Term 6  </th><th>Term 7  </th><th>Term 8  </th><th>Term 9  </th><th>Term 10  </th><th>Dist.  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>Topic 1  </td><td>like    </td><td>taste   </td><td>fast    </td><td>shake   </td><td>eat     </td><td>try     </td><td>fresh   </td><td>think   </td><td>have    </td><td>time     </td><td>16.51% </td></tr>\n",
       "<tr><td>Topic 2  </td><td>vegas   </td><td>location</td><td>fast    </td><td>this    </td><td>have    </td><td>time    </td><td>strip   </td><td>fresh   </td><td>visit   </td><td>menu     </td><td>13.16% </td></tr>\n",
       "<tr><td>Topic 3  </td><td>service </td><td>great   </td><td>friendly</td><td>location</td><td>staff   </td><td>clean   </td><td>fast    </td><td>this    </td><td>busy    </td><td>love     </td><td>19.64% </td></tr>\n",
       "<tr><td>Topic 4  </td><td>style   </td><td>double  </td><td>animal  </td><td>onion   </td><td>cheese  </td><td>grill   </td><td>order   </td><td>menu    </td><td>shake   </td><td>secret   </td><td>20.19% </td></tr>\n",
       "<tr><td>Topic 5  </td><td>line    </td><td>wait    </td><td>long    </td><td>drive   </td><td>love    </td><td>fast    </td><td>time    </td><td>eat     </td><td>like    </td><td>order    </td><td>13.63% </td></tr>\n",
       "<tr><td>Topic 6  </td><td>order   </td><td>time    </td><td>get     </td><td>go      </td><td>drive   </td><td>location</td><td>come    </td><td>like    </td><td>take    </td><td>wait     </td><td>15.64% </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "# In-N-Out Burger: 8 topics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>Topic #  </th><th>Term 1  </th><th>Term 2  </th><th>Term 3  </th><th>Term 4  </th><th>Term 5  </th><th>Term 6  </th><th>Term 7  </th><th>Term 8  </th><th>Term 9  </th><th>Term 10  </th><th>Dist.  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>Topic 1  </td><td>like    </td><td>taste   </td><td>bun     </td><td>patty   </td><td>meat    </td><td>fresh   </td><td>eat     </td><td>shake   </td><td>lettuce </td><td>try      </td><td>10.07% </td></tr>\n",
       "<tr><td>Topic 2  </td><td>location</td><td>time    </td><td>strip   </td><td>wait    </td><td>vegas   </td><td>close   </td><td>this    </td><td>fresh   </td><td>have    </td><td>get      </td><td>7.50%  </td></tr>\n",
       "<tr><td>Topic 3  </td><td>service </td><td>great   </td><td>friendly</td><td>location</td><td>staff   </td><td>clean   </td><td>fast    </td><td>this    </td><td>busy    </td><td>love     </td><td>18.24% </td></tr>\n",
       "<tr><td>Topic 4  </td><td>style   </td><td>animal  </td><td>double  </td><td>onion   </td><td>cheese  </td><td>grill   </td><td>order   </td><td>extra   </td><td>shake   </td><td>menu     </td><td>15.34% </td></tr>\n",
       "<tr><td>Topic 5  </td><td>line    </td><td>wait    </td><td>long    </td><td>love    </td><td>drive   </td><td>fast    </td><td>order   </td><td>eat     </td><td>fresh   </td><td>like     </td><td>10.45% </td></tr>\n",
       "<tr><td>Topic 6  </td><td>order   </td><td>drive   </td><td>go      </td><td>time    </td><td>get     </td><td>location</td><td>take    </td><td>come    </td><td>wait    </td><td>like     </td><td>13.22% </td></tr>\n",
       "<tr><td>Topic 7  </td><td>vegas   </td><td>coast   </td><td>double  </td><td>time    </td><td>west    </td><td>east    </td><td>try     </td><td>eat     </td><td>animal  </td><td>come     </td><td>10.36% </td></tr>\n",
       "<tr><td>Topic 8  </td><td>fast    </td><td>menu    </td><td>like    </td><td>fresh   </td><td>price   </td><td>secret  </td><td>quality </td><td>have    </td><td>chain   </td><td>eat      </td><td>12.74% </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "# In-N-Out Burger: 10 topics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>Topic #  </th><th>Term 1  </th><th>Term 2  </th><th>Term 3  </th><th>Term 4  </th><th>Term 5  </th><th>Term 6  </th><th>Term 7  </th><th>Term 8  </th><th>Term 9  </th><th>Term 10   </th><th>Dist.  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>Topic 1  </td><td>like    </td><td>taste   </td><td>bun     </td><td>patty   </td><td>fresh   </td><td>meat    </td><td>lettuce </td><td>shake   </td><td>sauce   </td><td>eat       </td><td>7.84%  </td></tr>\n",
       "<tr><td>Topic 2  </td><td>time    </td><td>have    </td><td>be      </td><td>vegas   </td><td>visit   </td><td>love    </td><td>location</td><td>eat     </td><td>live    </td><td>california</td><td>5.40%  </td></tr>\n",
       "<tr><td>Topic 3  </td><td>service </td><td>great   </td><td>friendly</td><td>fast    </td><td>staff   </td><td>clean   </td><td>location</td><td>customer</td><td>employee</td><td>this      </td><td>14.90% </td></tr>\n",
       "<tr><td>Topic 4  </td><td>animal  </td><td>style   </td><td>double  </td><td>shake   </td><td>vegas   </td><td>cheese  </td><td>menu    </td><td>get     </td><td>order   </td><td>secret    </td><td>7.54%  </td></tr>\n",
       "<tr><td>Topic 5  </td><td>love    </td><td>fresh   </td><td>animal  </td><td>style   </td><td>menu    </td><td>fast    </td><td>try     </td><td>simple  </td><td>eat     </td><td>shake     </td><td>9.94%  </td></tr>\n",
       "<tr><td>Topic 6  </td><td>order   </td><td>go      </td><td>get     </td><td>time    </td><td>drive   </td><td>come    </td><td>take    </td><td>like    </td><td>ask     </td><td>eat       </td><td>11.49% </td></tr>\n",
       "<tr><td>Topic 7  </td><td>coast   </td><td>west    </td><td>east    </td><td>time    </td><td>try     </td><td>know    </td><td>eat     </td><td>visit   </td><td>this    </td><td>come      </td><td>6.19%  </td></tr>\n",
       "<tr><td>Topic 8  </td><td>fast    </td><td>like    </td><td>menu    </td><td>people  </td><td>have    </td><td>chain   </td><td>eat     </td><td>think   </td><td>joint   </td><td>price     </td><td>9.86%  </td></tr>\n",
       "<tr><td>Topic 9  </td><td>location</td><td>line    </td><td>wait    </td><td>long    </td><td>drive   </td><td>busy    </td><td>this    </td><td>time    </td><td>order   </td><td>get       </td><td>13.42% </td></tr>\n",
       "<tr><td>Topic 10 </td><td>double  </td><td>style   </td><td>animal  </td><td>onion   </td><td>grill   </td><td>order   </td><td>cheese  </td><td>extra   </td><td>protein </td><td>like      </td><td>10.73% </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for num_topics in [6, 8, 10]:\n",
    "    lda_model = gensim.models.ldamulticore.LdaMulticore(corpus=corpus,\n",
    "                                                        id2word=dictionary,\n",
    "                                                        num_topics=num_topics, \n",
    "                                                        random_state=1,\n",
    "                                                        chunksize=500,\n",
    "                                                        passes=30,\n",
    "                                                        workers=7,\n",
    "                                                        per_word_topics=True)\n",
    "\n",
    "    results = []\n",
    "    topic_num = 1\n",
    "    for _, text in lda_model.print_topics():\n",
    "        results.append([\"Topic \" + str(topic_num)] + [re.findall('[a-z]+', x)[0] for x in text.split(' + ')])\n",
    "        topic_num += 1\n",
    "    \n",
    "    dist = {}\n",
    "    \n",
    "    for c in corpus:\n",
    "        topic_distribution = lda_model.get_document_topics(c)\n",
    "        for topic_index, distribution in topic_distribution:\n",
    "            if topic_index not in dist:\n",
    "                dist[topic_index] = 0\n",
    "            dist[topic_index] += distribution\n",
    "    \n",
    "    for topic_index, distribution in dist.items():\n",
    "        results[topic_index].append(\"%.2f\" % (distribution * 100 / len(corpus)) + \"%\")\n",
    "        \n",
    "    display(Markdown(\"# \" + business_name + \": \" + str(num_topics) + \" topics\"))\n",
    "    display(HTML(tabulate(results, tablefmt=\"html\", headers=[\"Topic #\"] + [\"Term \" + str(x) for x in range(1, 11)] + [\"Dist.\"])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Word2Vec Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building model from reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-13T03:47:16.627789Z",
     "start_time": "2019-04-13T03:47:16.624804Z"
    }
   },
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from gensim.models.phrases import Phraser, Phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-12T14:55:49.419052Z",
     "start_time": "2019-04-12T14:55:49.336130Z"
    }
   },
   "outputs": [],
   "source": [
    "df1 = pd.read_parquet(\"data/Shake Shack_reviews.parquet\")\n",
    "df2 = pd.read_parquet(\"data/In-N-Out Burger_reviews.parquet\")\n",
    "df3 = pd.read_parquet(\"data/The Cheesecake Factory_reviews.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-12T15:05:51.394363Z",
     "start_time": "2019-04-12T15:05:51.390376Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18314"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-12T14:58:12.131154Z",
     "start_time": "2019-04-12T14:56:48.956575Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "827cb5c15003472999d9339ad373f790",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=18314), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tokens = df1.text.append(df2.text).append(df3.text).progress_apply(tokenise)\n",
    "tokens = list(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-12T14:58:19.090678Z",
     "start_time": "2019-04-12T14:58:12.132151Z"
    }
   },
   "outputs": [],
   "source": [
    "# common_terms = [\"of\", \"with\", \"without\", \"and\", \"or\", \"the\", \"a\"]\n",
    "# Create the relevant phrases from the list of sentences:\n",
    "phrases = Phrases(tokens)\n",
    "# The Phraser object is used from now on to transform sentences\n",
    "bigram = Phraser(phrases)\n",
    "# Applying the Phraser to transform our sentences is simply\n",
    "new_tokens = list(bigram[tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-12T15:07:55.470491Z",
     "start_time": "2019-04-12T15:07:02.901304Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23923760, 36534080)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = gensim.models.Word2Vec(\n",
    "    new_tokens,\n",
    "    sg=1,\n",
    "    size=150,\n",
    "    window=7,\n",
    "    min_count=3,\n",
    "    workers=7)\n",
    "model.train(new_tokens, total_examples=len(new_tokens), epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-12T15:32:18.767701Z",
     "start_time": "2019-04-12T15:32:18.669843Z"
    }
   },
   "outputs": [],
   "source": [
    "model.save(\"models/word2vec_3biz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-12T15:11:59.399309Z",
     "start_time": "2019-04-12T15:11:59.395348Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('customer_service', 0.6847555637359619),\n",
       " ('staff', 0.5711835026741028),\n",
       " ('dante', 0.5680903792381287),\n",
       " ('tentative', 0.5398862361907959),\n",
       " ('heather', 0.5392563343048096),\n",
       " ('brenda', 0.5234328508377075),\n",
       " ('consistant', 0.518193244934082),\n",
       " ('food', 0.5143879652023315),\n",
       " ('absolutly', 0.5086746215820312),\n",
       " ('ethic', 0.5067006349563599)]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive='service')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-12T15:25:32.508043Z",
     "start_time": "2019-04-12T15:25:31.730020Z"
    }
   },
   "outputs": [],
   "source": [
    "model.wv.save_word2vec_format(\"models/w2v.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-12T15:24:10.531637Z",
     "start_time": "2019-04-12T15:24:10.256139Z"
    }
   },
   "outputs": [],
   "source": [
    "model.wv.save_word2vec_format('models/w2v', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-12T15:29:08.237434Z",
     "start_time": "2019-04-12T15:29:08.188565Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yenter\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.wv.vectors instead).\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.blank('en')\n",
    "\n",
    "keys = []\n",
    "for idx in range(len(model.wv.vocab)):\n",
    "    keys.append(model.wv.index2word[idx])\n",
    "\n",
    "nlp.vocab.vectors = spacy.vocab.Vectors(data=model.wv.syn0, keys=keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading model from disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-13T06:02:09.154904Z",
     "start_time": "2019-04-13T06:02:08.475689Z"
    }
   },
   "outputs": [],
   "source": [
    "model = Word2Vec.load('models/w2v.obj')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-13T06:02:10.521377Z",
     "start_time": "2019-04-13T06:02:10.475500Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('service-', 0.7543092966079712),\n",
       " ('Service', 0.7183818817138672),\n",
       " ('sevice', 0.678348183631897),\n",
       " ('waitstaff', 0.6351033449172974),\n",
       " ('staff', 0.6129365563392639),\n",
       " ('serivce', 0.5980651378631592),\n",
       " ('-service', 0.5541418194770813),\n",
       " ('Waitstaff', 0.5533532500267029),\n",
       " ('Server', 0.5380331873893738),\n",
       " ('SERVICE', 0.5359606742858887)]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive=['service'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-13T03:51:27.031512Z",
     "start_time": "2019-04-13T03:51:26.826061Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yenter\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.wv.vectors instead).\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.blank('en')\n",
    "\n",
    "keys = []\n",
    "for idx in range(len(model.wv.vocab)):\n",
    "    keys.append(model.wv.index2word[idx])\n",
    "\n",
    "nlp.vocab.vectors = spacy.vocab.Vectors(data=model.wv.syn0, keys=keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-13T03:52:06.997753Z",
     "start_time": "2019-04-13T03:52:06.992774Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reasonably priced"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp('reasonably priced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-13T03:50:48.611645Z",
     "start_time": "2019-04-13T03:50:48.457973Z"
    }
   },
   "outputs": [],
   "source": [
    "bigram = Phraser.load('models/bigram.obj')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-13T04:09:06.612714Z",
     "start_time": "2019-04-13T04:09:06.601744Z"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'float' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-55-4bd2529f29f7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbigram\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Customer\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Service\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\gensim\\models\\phrases.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, sentence)\u001b[0m\n\u001b[0;32m    624\u001b[0m             scorer=None)  # we will use our score_item function redefinition\n\u001b[0;32m    625\u001b[0m         \u001b[0mnew_s\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 626\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mwords\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscore\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbigrams\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    627\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mscore\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    628\u001b[0m                 \u001b[0mwords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\gensim\\models\\phrases.py\u001b[0m in \u001b[0;36manalyze_sentence\u001b[1;34m(self, sentence, threshold, common_terms, scorer)\u001b[0m\n\u001b[0;32m    165\u001b[0m                     \u001b[0mwordb\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    166\u001b[0m                     \u001b[0mcomponents\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mchain\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 167\u001b[1;33m                     \u001b[0mscorer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscorer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    168\u001b[0m                 )\n\u001b[0;32m    169\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mscore\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\gensim\\models\\phrases.py\u001b[0m in \u001b[0;36mscore_item\u001b[1;34m(self, worda, wordb, components, scorer)\u001b[0m\n\u001b[0;32m    596\u001b[0m         \"\"\"\n\u001b[0;32m    597\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 598\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mphrasegrams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcomponents\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    599\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    600\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'float' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "list(bigram[[\"Customer\", \"Service\"]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
